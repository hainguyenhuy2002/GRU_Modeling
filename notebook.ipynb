{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set has 7887595 Events,  1986830 Sessions, and 27353 Items\n",
      "\n",
      "\n",
      "Validation Set has 17707 Events,  3785 Sessions, and 3160 Items\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Sep 10 09:50:45 2019\n",
    "@author: s-moh\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# dataBefore = 'C:/Users/s-moh/0-Labwork/Rakuten Project/Dataset/RecSys_Dataset_Before/yoochoose-clicks.dat' #Path to Original Training Dataset \"Clicks\" File\n",
    "dataTestBefore = '/home/hainh/coccoc/code/week11/GRU4REC-pytorch/Dataset/raw_data/yoochoose-test.dat' #Path to Original Testing Dataset \"Clicks\" File\n",
    "# dataAfter = 'C:/Users/s-moh/0-Labwork/Rakuten Project/Dataset/RecSys_Dataset_After/' #Path to Processed Dataset Folder\n",
    "dayTime = 86400 #Validation Only one day = 86400 seconds\n",
    "\n",
    "def removeShortSessions(data):\n",
    "    #delete sessions of length < 1\n",
    "    sessionLen = data.groupby('SessionID').size() #group by sessionID and get size of each session\n",
    "    data = data[np.in1d(data.SessionID, sessionLen[sessionLen > 1].index)]\n",
    "    return data\n",
    "\n",
    "#Read Dataset in pandas Dataframe (Ignore Category Column)\n",
    "train = pd.read_csv(dataTestBefore, sep=',', header=None, usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n",
    "# test = pd.read_csv(dataTestBefore, sep=',', header=None, usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n",
    "train.columns = ['SessionID', 'Time', 'ItemID'] #Headers of dataframe\n",
    "# test.columns = ['SessionID', 'Time', 'ItemID'] #Headers of dataframe\n",
    "train['Time']= train.Time.apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()) #Convert time objects to timestamp\n",
    "# test['Time'] = test.Time.apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp()) #Convert time objects to timestamp\n",
    "\n",
    "#remove sessions of less than 2 interactions\n",
    "train = removeShortSessions(train)\n",
    "#delete records of items which appeared less than 5 times\n",
    "itemLen = train.groupby('ItemID').size() #groupby itemID and get size of each item\n",
    "train = train[np.in1d(train.ItemID, itemLen[itemLen > 4].index)]\n",
    "#remove sessions of less than 2 interactions again\n",
    "train = removeShortSessions(train)\n",
    "\n",
    "######################################################################################################3\n",
    "'''\n",
    "#Separate Data into Train and Test Splits\n",
    "timeMax = data.Time.max() #maximum time in all records\n",
    "sessionMaxTime = data.groupby('SessionID').Time.max() #group by sessionID and get the maximum time of each session\n",
    "sessionTrain = sessionMaxTime[sessionMaxTime < (timeMax - dayTime)].index #training split is all sessions that ended before the last day\n",
    "sessionTest  = sessionMaxTime[sessionMaxTime >= (timeMax - dayTime)].index #testing split is all sessions has records in the last day\n",
    "train = data[np.in1d(data.SessionID, sessionTrain)]\n",
    "test = data[np.in1d(data.SessionID, sessionTest)]\n",
    "'''\n",
    "#Delete records in testing split where items are not in training split\n",
    "# test = test[np.in1d(test.ItemID, train.ItemID)]\n",
    "#Delete Sessions in testing split which are less than 2\n",
    "# test = removeShortSessions(test)\n",
    "\n",
    "#Convert To CSV\n",
    "#print('Full Training Set has', len(train), 'Events, ', train.SessionID.nunique(), 'Sessions, and', train.ItemID.nunique(), 'Items\\n\\n')\n",
    "#train.to_csv(dataAfter + 'recSys15TrainFull.txt', sep='\\t', index=False)\n",
    "# print('Testing Set has', len(test), 'Events, ', test.SessionID.nunique(), 'Sessions, and', test.ItemID.nunique(), 'Items\\n\\n')\n",
    "#test.to_csv(dataAfter + 'recSys15Test.txt', sep=',', index=False)\n",
    "\n",
    "######################################################################################################3\n",
    "#Separate Training set into Train and Validation Splits\n",
    "timeMax = train.Time.max()\n",
    "sessionMaxTime = train.groupby('SessionID').Time.max()\n",
    "sessionTrain = sessionMaxTime[sessionMaxTime < (timeMax - dayTime)].index #training split is all sessions that ended before the last 2nd day\n",
    "sessionValid = sessionMaxTime[sessionMaxTime >= (timeMax - dayTime)].index #validation split is all sessions that ended during the last 2nd day\n",
    "trainTR = train[np.in1d(train.SessionID, sessionTrain)]\n",
    "trainVD = train[np.in1d(train.SessionID, sessionValid)]\n",
    "#Delete records in validation split where items are not in training split\n",
    "trainVD = trainVD[np.in1d(trainVD.ItemID, trainTR.ItemID)]\n",
    "#Delete Sessions in testing split which are less than 2\n",
    "trainVD = removeShortSessions(trainVD)\n",
    "#Convert To CSV\n",
    "print('Training Set has', len(trainTR), 'Events, ', trainTR.SessionID.nunique(), 'Sessions, and', trainTR.ItemID.nunique(), 'Items\\n\\n')\n",
    "#trainTR.to_csv(dataAfter + 'recSys15TrainOnly.txt', sep=',', index=False)\n",
    "print('Validation Set has', len(trainVD), 'Events, ', trainVD.SessionID.nunique(), 'Sessions, and', trainVD.ItemID.nunique(), 'Items\\n\\n')\n",
    "#trainVD.to_csv(dataAfter + 'recSys15Valid.txt', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionID</th>\n",
       "      <th>Time</th>\n",
       "      <th>ItemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1.396866e+09</td>\n",
       "      <td>214530776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.396866e+09</td>\n",
       "      <td>214530776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.396866e+09</td>\n",
       "      <td>214530776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.396572e+09</td>\n",
       "      <td>214820942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1.396572e+09</td>\n",
       "      <td>214826810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251786</th>\n",
       "      <td>11299820</td>\n",
       "      <td>1.411608e+09</td>\n",
       "      <td>214853094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251787</th>\n",
       "      <td>11299815</td>\n",
       "      <td>1.411700e+09</td>\n",
       "      <td>214854804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251788</th>\n",
       "      <td>11299815</td>\n",
       "      <td>1.411700e+09</td>\n",
       "      <td>214714715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251789</th>\n",
       "      <td>11299810</td>\n",
       "      <td>1.411722e+09</td>\n",
       "      <td>214546123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251790</th>\n",
       "      <td>11299810</td>\n",
       "      <td>1.411722e+09</td>\n",
       "      <td>214546123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7887595 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SessionID          Time     ItemID\n",
       "0                5  1.396866e+09  214530776\n",
       "1                5  1.396866e+09  214530776\n",
       "2                5  1.396866e+09  214530776\n",
       "3               10  1.396572e+09  214820942\n",
       "4               10  1.396572e+09  214826810\n",
       "...            ...           ...        ...\n",
       "8251786   11299820  1.411608e+09  214853094\n",
       "8251787   11299815  1.411700e+09  214854804\n",
       "8251788   11299815  1.411700e+09  214714715\n",
       "8251789   11299810  1.411722e+09  214546123\n",
       "8251790   11299810  1.411722e+09  214546123\n",
       "\n",
       "[7887595 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionID</th>\n",
       "      <th>Time</th>\n",
       "      <th>ItemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8046986</th>\n",
       "      <td>11264965</td>\n",
       "      <td>1.411980e+09</td>\n",
       "      <td>214545928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046987</th>\n",
       "      <td>11264965</td>\n",
       "      <td>1.411980e+09</td>\n",
       "      <td>214545928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047046</th>\n",
       "      <td>11264880</td>\n",
       "      <td>1.411992e+09</td>\n",
       "      <td>214516112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047047</th>\n",
       "      <td>11264880</td>\n",
       "      <td>1.411993e+09</td>\n",
       "      <td>214692868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047048</th>\n",
       "      <td>11264880</td>\n",
       "      <td>1.411993e+09</td>\n",
       "      <td>214561678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251757</th>\n",
       "      <td>11299785</td>\n",
       "      <td>1.411988e+09</td>\n",
       "      <td>214858792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251758</th>\n",
       "      <td>11299785</td>\n",
       "      <td>1.411988e+09</td>\n",
       "      <td>214858905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251759</th>\n",
       "      <td>11299785</td>\n",
       "      <td>1.411988e+09</td>\n",
       "      <td>214857701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251760</th>\n",
       "      <td>11299785</td>\n",
       "      <td>1.411988e+09</td>\n",
       "      <td>214556563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251761</th>\n",
       "      <td>11299785</td>\n",
       "      <td>1.411989e+09</td>\n",
       "      <td>214858691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SessionID          Time     ItemID\n",
       "8046986   11264965  1.411980e+09  214545928\n",
       "8046987   11264965  1.411980e+09  214545928\n",
       "8047046   11264880  1.411992e+09  214516112\n",
       "8047047   11264880  1.411993e+09  214692868\n",
       "8047048   11264880  1.411993e+09  214561678\n",
       "...            ...           ...        ...\n",
       "8251757   11299785  1.411988e+09  214858792\n",
       "8251758   11299785  1.411988e+09  214858905\n",
       "8251759   11299785  1.411988e+09  214857701\n",
       "8251760   11299785  1.411988e+09  214556563\n",
       "8251761   11299785  1.411989e+09  214858691\n",
       "\n",
       "[17707 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "model = load_model_checkpoint('gru4rec_checkpoint')\n",
    "\n",
    "# Preprocess the input sequence\n",
    "preprocessed_sequence = preprocess_input_sequence(input_sequence)\n",
    "\n",
    "# Forward pass through the model\n",
    "predictions = model.predict(preprocessed_sequence)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_item = get_predicted_item(predictions)\n",
    "\n",
    "# Print the predicted item\n",
    "print('Predicted item:', predicted_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lib.Dataset('/home/hainh/coccoc/code/week11/GRU4REC-pytorch/Dataset/RecSys_Dataset_After/recSys15TrainOnly.txt')\n",
    "# valid_data = lib.Dataset(, itemmap=train_data.itemmap)\n",
    "\n",
    "#set all the parameters according to the defined arguments\n",
    "input_size = len(train_data.items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GRU4REC:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"args\", \"epoch\", \"optim\", \"loss\", \"recall\", \"mrr\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load the model checkpoint\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m GRU4REC(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/hainh/coccoc/code/week11/GRU4REC-pytorch/checkpoint/06072142/model_00004.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define a function to preprocess the input sequence\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2035'>2036</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2036'>2037</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2037'>2038</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2039'>2040</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2040'>2041</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2041'>2042</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2042'>2043</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GRU4REC:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"args\", \"epoch\", \"optim\", \"loss\", \"recall\", \"mrr\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the GRU4REC model architecture\n",
    "class GRU4REC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU4REC, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.gru(x)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return output\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = GRU4REC(16, 100, 16)\n",
    "model.load_state_dict(torch.load('/home/hainh/coccoc/code/week11/GRU4REC-pytorch/checkpoint/06072142/model_00004.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Define a function to preprocess the input sequence\n",
    "def preprocess_input_sequence(input_sequence):\n",
    "    # Perform any necessary preprocessing on the input sequence\n",
    "    # For example, you might convert the sequence to a tensor\n",
    "    preprocessed_sequence = torch.tensor(input_sequence, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return preprocessed_sequence\n",
    "\n",
    "# Define a function to interpret the model's predictions\n",
    "def get_predicted_item(predictions):\n",
    "    # Extract the predicted item from the model's predictions\n",
    "    predicted_item = torch.argmax(predictions).item()\n",
    "    \n",
    "    return predicted_item\n",
    "\n",
    "# Define your input sequence\n",
    "input_sequence = [1, 2, 3, 4, 5]  # Example input sequence\n",
    "\n",
    "# Preprocess the input sequence\n",
    "preprocessed_sequence = preprocess_input_sequence(input_sequence)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(preprocessed_sequence)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_item = get_predicted_item(predictions)\n",
    "\n",
    "# Print the predicted item\n",
    "print('Predicted item:', predicted_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GRU4REC:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"args\", \"epoch\", \"optim\", \"loss\", \"recall\", \"mrr\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load the model checkpoint\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m GRU4REC(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/hainh/coccoc/code/week11/GRU4REC-pytorch/checkpoint/06072142/model_00004.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define a function to preprocess the input sequence\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2035'>2036</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2036'>2037</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2037'>2038</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2039'>2040</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2040'>2041</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2041'>2042</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/hainh/anaconda3/envs/sea/lib/python3.11/site-packages/torch/nn/modules/module.py?line=2042'>2043</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GRU4REC:\n\tMissing key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"args\", \"epoch\", \"optim\", \"loss\", \"recall\", \"mrr\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the GRU4REC model architecture\n",
    "class GRU4REC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU4REC, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.gru(x)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return output\n",
    "\n",
    "# Load the model checkpoint\n",
    "model = GRU4REC(16, 100, 16)\n",
    "model.load_state_dict(torch.load('/home/hainh/coccoc/code/week11/GRU4REC-pytorch/checkpoint/06072142/model_00004.pt',  map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Define a function to preprocess the input sequence\n",
    "def preprocess_input_sequence(input_sequence):\n",
    "    # Perform any necessary preprocessing on the input sequence\n",
    "    # For example, you might convert the sequence to a tensor\n",
    "    preprocessed_sequence = torch.tensor(input_sequence, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return preprocessed_sequence\n",
    "\n",
    "# Define a function to interpret the model's predictions\n",
    "def get_predicted_item(predictions):\n",
    "    # Extract the predicted item from the model's predictions\n",
    "    predicted_item = torch.argmax(predictions).item()\n",
    "    \n",
    "    return predicted_item\n",
    "\n",
    "# Define your input sequence\n",
    "input_sequence = [1, 2, 3, 4, 5]  # Example input sequence\n",
    "\n",
    "# Preprocess the input sequence\n",
    "preprocessed_sequence = preprocess_input_sequence(input_sequence)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(preprocessed_sequence)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_item = get_predicted_item(predictions)\n",
    "\n",
    "# Print the predicted item\n",
    "print('Predicted item:', predicted_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4244f09a54cc152c57f791beff0a88d5b7a0c3fb03ea8cdaea2cfe0f3026c47"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('sea': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
